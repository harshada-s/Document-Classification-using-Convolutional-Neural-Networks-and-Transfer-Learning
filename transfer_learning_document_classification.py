# -*- coding: utf-8 -*-
"""Transfer_Learning_Document_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hsQF-qQrGxpovt4cNHlwc2hpDq3lwlUv
"""

# -*- coding: utf-8 -*-
#DOWNLOAD THE DATASET

from keras.preprocessing.image import ImageDataGenerator

!pip install opendatasets

import opendatasets as op

op.download("https://www.kaggle.com/datasets/muhammadumer2002/rvl-cdip")



accuraciest=[]

accuracy=[]
recalls=[]
precision=[]

models=['VGG19','InceptionV3','VGG16']

##DOWNLOAD THE DATASET

op.download("https://www.kaggle.com/datasets/pdavpoojan/the-rvlcdip-dataset-test")

#op.download("https://www.kaggle.com/datasets/muhammadumer2002/rvl-cdip")

from keras.preprocessing.image import ImageDataGenerator

#!pip install opendatasets
datasetFolder = "rvl-cdip/train/"

datasetFolder1 = "rvl-cdip/val/"

datasetFolder2="the-rvlcdip-dataset-test/test/"
import opendatasets as op



import pathlib
import os
train = pathlib.Path(os.path.join(datasetFolder))
test=pathlib.Path(os.path.join(datasetFolder2))
val=pathlib.Path(os.path.join(datasetFolder1))

#print(train)

import pandas as pd
import numpy as np
import tensorflow as tf
import string
import nltk
import pathlib
import os
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives, BinaryAccuracy, Precision, Recall, AUC






from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
rescale = 1./255)
test_datagen = ImageDataGenerator(
rescale = 1./255)
cv_datagen = ImageDataGenerator(
rescale = 1./255)






from keras.optimizers import Adam

from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
rescale = 1./255)
test_datagen = ImageDataGenerator()
cv_datagen = ImageDataGenerator()

test_it = test_datagen.flow_from_directory('rvl-cdip/val/',batch_size=32,target_size=(256, 256))
train_t = train_datagen.flow_from_directory('rvl-cdip/train/',batch_size=32,target_size=(256, 256),class_mode='categorical')

def get_images_labels(images, label):
  arr = []
  labels = []
  for i in images:
    img = cv2.imread(os.path.join(i))
    img = cv2.resize(img, (256, 256))
    arr.append(img)
    labels.append(label)
  return [arr, labels]

#Training Data
[form, Y_form] = get_images_labels(list(train.glob("form/*.*")), 0)
[invoice, Y_invoice] = get_images_labels(list(train.glob("invoice/*.*")), 1)
[letter, Y_letter] = get_images_labels(list(train.glob("letter/*.*")), 2)
[resume, Y_resume] = get_images_labels(list(train.glob("resume/*.*")), 3)



train_images = form + invoice + letter + resume
train_labels =  Y_form +Y_invoice+ Y_letter +Y_resume

train_images = np.asarray(train_images)
train_labels = np.asarray(train_labels)

train_labels = to_categorical(train_labels)



#Testing data
[form, Y_form] = get_images_labels(list(val.glob("form/*.*")), 0)
[invoice, Y_invoice] = get_images_labels(list(val.glob("invoice/*.*")), 1)
[letter, Y_letter] = get_images_labels(list(val.glob("letter/*.*")), 2)
[resume, Y_resume] = get_images_labels(list(val.glob("resume/*.*")), 3)

test_images = form + invoice + letter +resume
test_labels =  Y_form +Y_invoice+ Y_letter +Y_resume

test_images = np.asarray(test_images)
test_labels = np.asarray(test_labels)

test_images.shape

test_labels = to_categorical(test_labels)



train_images[0].shape



#Validation Data
[form, Y_form] = get_images_labels(list(test.glob("form/*.*")), 0)
[invoice, Y_invoice] = get_images_labels(list(test.glob("invoice/*.*")), 1)
[letter, Y_letter] = get_images_labels(list(test.glob("letter/*.*")), 2)
[resume, Y_resume] = get_images_labels(list(test.glob("resume/*.*")), 3)

val_images = form + invoice + letter +resume
val_labels =  Y_form +Y_invoice+ Y_letter +Y_resume

val_images = np.asarray(val_images)
val_labels = np.asarray(val_labels)
val_labels = to_categorical(val_labels)

#FINE TUNING THE PRE TRAINED MODELS

from keras.optimizers import Adam
from keras import applications
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential, Model 
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D
from keras import backend as k 
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping
import keras
img_width, img_height = 256,256
batch_size = 32
epochs = 50

model = tf.keras.applications.VGG19(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3),)
#model = tf.keras.applications.inception_v3.InceptionV3(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3),)

from keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=2, min_lr=0.000001)
mcp_save = ModelCheckpoint('model_3.hdf5', save_best_only=True, monitor='acc', mode='max')

from keras.layers import GlobalAveragePooling2D

for layer in model.layers:
  layer.trainable=True

#Adding custom Layers 

x = model.output

x = Flatten()(x)
x = Dense(256, activation="relu")(x)
x = Dropout(0.5)(x)
x = Dense(128, activation="relu")(x)
predictions = Dense(4, activation="softmax")(x)

# creating the final model 
model_final = Model(inputs = model.input, outputs = predictions)

# compile the model 
model_final.compile(loss = "categorical_crossentropy", optimizer =Adam(lr=0.0001), metrics=["accuracy"])

model_final.summary()

history=model_final.fit(
train_images,train_labels,steps_per_epoch =31175/32, epochs=6,validation_data=(val_images,val_labels), validation_steps=9983/32,
callbacks=[reduce_lr,mcp_save])

from tensorflow import keras

def plt_dynamic(x,ty,colors=['b']):
    ax.plot(x, ty, 'r', label="Training Accuracy")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

def plt_dynamics(x,ty,colors=['b']):
    ax.plot(x, ty, 'b', label="Validation Accuracy")
    plt.legend()
    plt.grid()
    fig.canvas.draw()


fig,ax = plt.subplots(1,1)
ax.set_xlabel('epochs') ; ax.set_ylabel('Accuracies')    
# list of epoch numbers
x = list(range(1,6+1))

ty = history.history['accuracy']
ty1=history.history['val_accuracy']
plt_dynamic(x,ty)
plt_dynamics(x,ty1)

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns

def plt_dynamic(x,ty,colors=['b']):
    ax.plot(x, ty, 'r', label="Train Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

def plt_dynamics(x,ty,colors=['b']):
    ax.plot(x, ty, 'b', label="Validation Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

# %matplotlib inline
sns.set_context('notebook')
# %config InlineBackend.figure_format = 'retina'


fig,ax = plt.subplots(1,1)
ax.set_xlabel('epochs') ; ax.set_ylabel('Categorical Crossentropy Loss')    
# list of epoch numbers
x = list(range(1,6+1))

ty = history.history['loss']
ty1=history.history['val_loss']
plt_dynamic(x,ty)
plt_dynamics(x,ty1)

from keras.optimizers import Adam
from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential, Model 
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D
from keras import backend as k 
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping
import keras
img_width, img_height = 256,256
batch_size = 32
epochs = 50

#model = tf.keras.applications.VGG19(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3),)
model = tf.keras.applications.resnet_v2.ResNet50V2(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3),)

from keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=2, min_lr=0.000001)
mcp_save = ModelCheckpoint('model_3.hdf5', save_best_only=True, monitor='acc', mode='max')

from keras.layers import GlobalAveragePooling2D

for layer in model.layers:
  layer.trainable=True

#Adding custom Layers 

x = model.output

x = Flatten()(x)
x = Dense(256, activation="relu")(x)
x = Dropout(0.5)(x)
x = Dense(128, activation="relu")(x)
predictions = Dense(4, activation="softmax")(x)

# creating the final model 
model_final1 = Model(inputs = model.input, outputs = predictions)

# compile the model 
model_final1.compile(loss = "categorical_crossentropy", optimizer =Adam(lr=0.0001), metrics=["accuracy"])

model_final1.summary()

history=model_final1.fit(
train_images,train_labels,steps_per_epoch =31172/32, epochs=6,validation_data=(val_images,val_labels), validation_steps=9983/32,
callbacks=[reduce_lr,mcp_save])

from tensorflow import keras

def plt_dynamic(x,ty,colors=['b']):
    ax.plot(x, ty, 'r', label="Training Accuracy")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

def plt_dynamics(x,ty,colors=['b']):
    ax.plot(x, ty, 'b', label="Validation Accuracy")
    plt.legend()
    plt.grid()
    fig.canvas.draw()


fig,ax = plt.subplots(1,1)
ax.set_xlabel('epochs') ; ax.set_ylabel('Accuracies')    
# list of epoch numbers
x = list(range(1,6+1))

ty = history.history['accuracy']
ty1=history.history['val_accuracy']
plt_dynamic(x,ty)
plt_dynamics(x,ty1)

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns

def plt_dynamic(x,ty,colors=['b']):
    ax.plot(x, ty, 'r', label="Train Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

def plt_dynamics(x,ty,colors=['b']):
    ax.plot(x, ty, 'b', label="Validation Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

# %matplotlib inline
sns.set_context('notebook')
# %config InlineBackend.figure_format = 'retina'


fig,ax = plt.subplots(1,1)
ax.set_xlabel('epochs') ; ax.set_ylabel('Categorical Crossentropy Loss')    
# list of epoch numbers
x = list(range(1,6+1))

ty = history.history['loss']
ty1=history.history['val_loss']
plt_dynamic(x,ty)
plt_dynamics(x,ty1)

from keras.optimizers import Adam
from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential, Model 
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D
from keras import backend as k 
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping
import keras
img_width, img_height = 256,256
batch_size = 32
epochs = 50

model = tf.keras.applications.VGG16(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3),)
#model = tf.keras.applications.resnet_v2.ResNet50V2(weights = "imagenet", include_top=False, input_shape = (img_width, img_height, 3),)

from keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=2, min_lr=0.000001)
mcp_save = ModelCheckpoint('model_3.hdf5', save_best_only=True, monitor='acc', mode='max')

from keras.layers import GlobalAveragePooling2D

for layer in model.layers:
  layer.trainable=True

#Adding custom Layers 

x = model.output

x = Flatten()(x)
x = Dense(256, activation="relu")(x)
x = Dropout(0.5)(x)
x = Dense(128, activation="relu")(x)
predictions = Dense(4, activation="softmax")(x)

# creating the final model 
model_final2 = Model(inputs = model.input, outputs = predictions)

# compile the model 
model_final2.compile(loss = "categorical_crossentropy", optimizer =Adam(lr=0.0001), metrics=["accuracy"])

model_final2.summary()

history=model_final1.fit(
train_images,train_labels,steps_per_epoch =31172/32, epochs=15,validation_data=(val_images,val_labels), validation_steps=9983/32,
callbacks=[reduce_lr,mcp_save])

from tensorflow import keras

def plt_dynamic(x,ty,colors=['b']):
    ax.plot(x, ty, 'r', label="Training Accuracy")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

def plt_dynamics(x,ty,colors=['b']):
    ax.plot(x, ty, 'b', label="Validation Accuracy")
    plt.legend()
    plt.grid()
    fig.canvas.draw()


fig,ax = plt.subplots(1,1)
ax.set_xlabel('epochs') ; ax.set_ylabel('Accuracies')    
# list of epoch numbers
x = list(range(1,6+1))

ty = history.history['accuracy']
ty1=history.history['val_accuracy']
plt_dynamic(x,ty)
plt_dynamics(x,ty1)

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns

def plt_dynamic(x,ty,colors=['b']):
    ax.plot(x, ty, 'r', label="Train Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

def plt_dynamics(x,ty,colors=['b']):
    ax.plot(x, ty, 'b', label="Validation Loss")
    plt.legend()
    plt.grid()
    fig.canvas.draw()

# %matplotlib inline
sns.set_context('notebook')
# %config InlineBackend.figure_format = 'retina'


fig,ax = plt.subplots(1,1)
ax.set_xlabel('epochs') ; ax.set_ylabel('Categorical Crossentropy Loss')    
# list of epoch numbers
x = list(range(1,6+1))

ty = history.history['loss']
ty1=history.history['val_loss']
plt_dynamic(x,ty)
plt_dynamics(x,ty1)

models=['VGG19','InceptionV3','VGG16','ResNet50']



from tensorflow import keras
model_final.save('model_inceptionV3.h5')

from tensorflow import keras
model_final1.save('model_resnet50.h5')

from tensorflow import keras
model_final2.save('model_vgg16.h5')

m = keras.models.load_model('model_inceptionV3.h5')

m1= keras.models.load_model('model_resnet50.h5')

m2= keras.models.load_model('model_vgg16.h5')



score=model_final.evaluate(test_images,test_labels,batch_size=32,workers=1, use_multiprocessing=True, verbose=0)
accuraciest.append(score)
#print(score)
print("The accuracy for model-Pretrained VGG 19 initiazlied with image net:",score[1]*100,"%")

score=model_final1.evaluate(test_images,test_labels,batch_size=32,workers=1, use_multiprocessing=True, verbose=0)
accuraciest.append(score)
#print(score)
print("The accuracy for model-Pretrained resnet50 initiazlied with image net:",score[1]*100,"%")

score=model_final2.evaluate(test_images,test_labels,batch_size=32,workers=1, use_multiprocessing=True, verbose=0)
accuraciest.append(score)
#print(score)
print("The accuracy for model-Pretrained vgg16 initiazlied with image net:",score[1]*100,"%")



#Prediction on test data
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
plt.figure(figsize =(16, 16))
img_path = "test_fom2.tif"
img = cv2.imread(img_path)
#img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
img = cv2.resize(img, (512, 512))
print(img.shape)
plt.imshow(img)
plt.show()
from sklearn import metrics
import numpy as np
import seaborn as sn



#Predictions on Test images passed as batch
Y_pred = m.predict(test_images)      
val_preds = np.argmax(Y_pred, axis=1)
y_test = np.argmax(test_labels, axis = 1)

from sklearn.metrics import accuracy_score,recall_score, precision_score,classification_report
print('Accuracy Score is',accuracy_score(y_test, val_preds))
accuracy.append(accuracy_score(y_test, val_preds))
print(recall_score(y_test, val_preds, average='weighted'))
print( precision_score(y_test, val_preds, average='weighted'))
recalls.append(recall_score(y_test, val_preds, average='weighted'))
precision.append( precision_score(y_test, val_preds, average='weighted'))
print(classification_report(y_test, val_preds))
#zipped = list(zip(models, accuracy, recalls,precision))
#df = pd.DataFrame(zipped, columns=['Models', 'Testing Accuracies', 'Recalls','Precision'])
#c=pd.DataFrame()

classes = list(range(4))
class_names=['form','invoice','letter','resume']
j=tf.math.confusion_matrix(val_preds,y_test)
tot=sum(j)
print(tot)
res = tf.math.confusion_matrix(val_preds,y_test).numpy()
cm = pd.DataFrame(res,
                     index = classes, 
                     columns = classes)

import seaborn as sns
figure = plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True,fmt="d",  xticklabels=class_names, yticklabels=class_names, cmap=plt.cm.Blues)
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
     
    
          

'''count=0
for i in range(len(val_trues)):
  if(val_preds[i] == val_trues[i]):
    print("The predicted class is : " , val_preds[i])
    print("The real class is : " , val_trues[i])
    count=count+1'''



#print('Accuracy score : %.3f' % metrics.accuracy_score(val_trues, val_preds))
#from sklearn.metrics import classification_report
#print(classification_report(val_trues, val_preds))


#Prediction on single image
import tensorflow
import keras
from keras.applications.vgg19 import preprocess_input, decode_predictions
img =image.load_img(img_path, target_size=(256, 256))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds=m.predict(x)
# create a list containing the class labels
class_labels = ['form','invoice','letter','resume']
# find the index of the class with maximum score
pred = np.argmax(preds, axis=-1)
# print the label of the class with maximum score
print('Predicted class is ',class_labels[pred[0]])


#confusion_mtx = [val_trues, val_preds]
#print(confusion_mtx)
#img = tf.keras.utils.load_img('test_invoice.tif', target_size=(256, 256))
#print(img.shape)
#img_array = tf.keras.utils.img_to_array(img)

#prediction = model_final.predict(img_array)
#print("predicted label for test image",np.argmax(prediction,axis=1))

#Prediction on test data
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
plt.figure(figsize =(16, 16))
img_path = "test_letter.tif"
img = cv2.imread(img_path)
#img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#img = cv2.resize(img, (256, 256))
print(img.shape)
plt.imshow(img)
plt.show()
from sklearn import metrics
import numpy as np
import seaborn as sn



#Predictions on Test images passed as batch
Y_pred = m1.predict(test_images)      
val_preds = np.argmax(Y_pred, axis=1)
y_test = np.argmax(test_labels, axis = 1)

from sklearn.metrics import accuracy_score,recall_score, precision_score,classification_report
print('Accuracy Score is',accuracy_score(y_test, val_preds))
accuracy.append(accuracy_score(y_test, val_preds))
print(recall_score(y_test, val_preds, average='weighted'))
print( precision_score(y_test, val_preds, average='weighted'))
recalls.append(recall_score(y_test, val_preds, average='weighted'))
precision.append( precision_score(y_test, val_preds, average='weighted'))
print(classification_report(y_test, val_preds))
#zipped = list(zip(models, accuracy, recalls,precision))
#df = pd.DataFrame(zipped, columns=['Models', 'Testing Accuracies', 'Recalls','Precision'])
#c=pd.DataFrame()

classes = list(range(4))
class_names=['form','invoice','letter','resume']
j=tf.math.confusion_matrix(val_preds,y_test)
tot=sum(j)
print(tot)
res = tf.math.confusion_matrix(val_preds,y_test).numpy()
cm = pd.DataFrame(res,
                     index = classes, 
                     columns = classes)

import seaborn as sns
figure = plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True,fmt="d",  xticklabels=class_names, yticklabels=class_names, cmap=plt.cm.Blues)
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
     
    
          

'''count=0
for i in range(len(val_trues)):
  if(val_preds[i] == val_trues[i]):
    print("The predicted class is : " , val_preds[i])
    print("The real class is : " , val_trues[i])
    count=count+1'''



#print('Accuracy score : %.3f' % metrics.accuracy_score(val_trues, val_preds))
#from sklearn.metrics import classification_report
#print(classification_report(val_trues, val_preds))


#Prediction on single image
import tensorflow
import keras
from keras.applications.vgg19 import preprocess_input, decode_predictions
img =image.load_img(img_path, target_size=(256, 256))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds=m.predict(x)
# create a list containing the class labels
class_labels = ['form','invoice','letter','resume']
# find the index of the class with maximum score
pred = np.argmax(preds, axis=-1)
# print the label of the class with maximum score
print(class_labels[pred[0]])


#confusion_mtx = [val_trues, val_preds]
#print(confusion_mtx)
#img = tf.keras.utils.load_img('test_invoice.tif', target_size=(256, 256))
#print(img.shape)
#img_array = tf.keras.utils.img_to_array(img)

#prediction = model_final.predict(img_array)
#print("predicted label for test image",np.argmax(prediction,axis=1))

#Prediction on test data
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
plt.figure(figsize =(16, 16))
img_path = "test_letter.tif"
img = cv2.imread(img_path)
#img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#img = cv2.resize(img, (256, 256))
print(img.shape)
plt.imshow(img)
plt.show()
from sklearn import metrics
import numpy as np
import seaborn as sn



#Predictions on Test images passed as batch
Y_pred = m2.predict(test_images)      
val_preds = np.argmax(Y_pred, axis=1)
y_test = np.argmax(test_labels, axis = 1)

from sklearn.metrics import accuracy_score,recall_score, precision_score,classification_report
print('Accuracy Score is',accuracy_score(y_test, val_preds))
accuracy.append(accuracy_score(y_test, val_preds))
print(recall_score(y_test, val_preds, average='weighted'))
print( precision_score(y_test, val_preds, average='weighted'))
recalls.append(recall_score(y_test, val_preds, average='weighted'))
precision.append( precision_score(y_test, val_preds, average='weighted'))
print(classification_report(y_test, val_preds))
#zipped = list(zip(models, accuracy, recalls,precision))
#df = pd.DataFrame(zipped, columns=['Models', 'Testing Accuracies', 'Recalls','Precision'])
#c=pd.DataFrame()

classes = list(range(4))
class_names=['form','invoice','letter','resume']
j=tf.math.confusion_matrix(val_preds,y_test)
tot=sum(j)
print(tot)
res = tf.math.confusion_matrix(val_preds,y_test).numpy()
cm = pd.DataFrame(res,
                     index = classes, 
                     columns = classes)

import seaborn as sns
figure = plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True,fmt="d",  xticklabels=class_names, yticklabels=class_names, cmap=plt.cm.Blues)
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
     
    
          

'''count=0
for i in range(len(val_trues)):
  if(val_preds[i] == val_trues[i]):
    print("The predicted class is : " , val_preds[i])
    print("The real class is : " , val_trues[i])
    count=count+1'''



#print('Accuracy score : %.3f' % metrics.accuracy_score(val_trues, val_preds))
#from sklearn.metrics import classification_report
#print(classification_report(val_trues, val_preds))


#Prediction on single image
import tensorflow
import keras
from keras.applications.vgg19 import preprocess_input, decode_predictions
img =image.load_img(img_path, target_size=(256, 256))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds=m.predict(x)
# create a list containing the class labels
class_labels = ['form','invoice','letter','resume']
# find the index of the class with maximum score
pred = np.argmax(preds, axis=-1)
# print the label of the class with maximum score
print(class_labels[pred[0]])



import pandas as pd
zipped = list(zip(models, accuracy, recalls,precision))
df = pd.DataFrame(zipped, columns=['Models', 'Testing Accuracies', 'Recall','Precision'])
df1=df.sort_values(by=['Testing Accuracies'],ascending=False,ignore_index=True)

df1

"""# New Section"""